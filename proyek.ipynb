{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4c7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2afdb3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimeSeriesRequestPredictor30Min:\n",
    "    def __init__(self, sequence_length=144, prediction_horizon=48):\n",
    "        \"\"\"\n",
    "        sequence_length: panjang window historis (slot 30 menit)\n",
    "        prediction_horizon: horizon prediksi (berapa slot 30 menit ke depan)\n",
    "        Default 144 slot = 3 hari * 48 slot/hari\n",
    "        \"\"\"\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        self.scaler = StandardScaler()\n",
    "        self.geo_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "\n",
    "    # ================================\n",
    "    # Preprocessing\n",
    "    # ================================\n",
    "    def load_and_preprocess_data(self, csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        df[\"request_date\"] = pd.to_datetime(df[\"request_date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "        # Ekstrak slot 30 menit\n",
    "        def extract_slot(val):\n",
    "            if pd.isna(val):\n",
    "                return -1\n",
    "            if isinstance(val, str) and \"-\" in val:\n",
    "                start = val.split(\"-\")[0]\n",
    "                h, m = map(int, start.split(\":\"))\n",
    "                return h*2 + (m//30)\n",
    "            try:\n",
    "                t = pd.to_datetime(val)\n",
    "                return t.hour*2 + (t.minute//30)\n",
    "            except:\n",
    "                return -1\n",
    "        df[\"slot_30min\"] = df[\"time_slot\"].apply(extract_slot)\n",
    "        df[\"is_missing_slot\"] = (df[\"slot_30min\"] == -1).astype(int)\n",
    "\n",
    "        # Encode geo_hash\n",
    "        df[\"geo_encoded\"] = self.geo_encoder.fit_transform(df[\"origin_geo_hash\"])\n",
    "\n",
    "        # Fitur temporal\n",
    "        df[\"day_of_week\"] = df[\"request_date\"].dt.dayofweek\n",
    "        df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype(int)\n",
    "\n",
    "        df = df.sort_values([\"origin_geo_hash\", \"request_date\", \"slot_30min\"])\n",
    "        return df\n",
    "\n",
    "    # ================================\n",
    "    # Sequence Generator dengan log-transform\n",
    "    # ================================\n",
    "    def create_sequences(self, data):\n",
    "        sequences, targets = [], []\n",
    "        features = [\"request_count\",\"slot_30min\",\"day_of_week\",\"is_weekend\",\"geo_encoded\"]\n",
    "\n",
    "        for geo_hash in data[\"origin_geo_hash\"].unique():\n",
    "            geo_data = data[data[\"origin_geo_hash\"]==geo_hash].sort_values([\"request_date\",\"slot_30min\"])\n",
    "            feature_data = geo_data[features].values.copy()\n",
    "\n",
    "            # Log-transform request_count\n",
    "            feature_data[:,0] = np.log1p(feature_data[:,0])\n",
    "\n",
    "            for i in range(len(feature_data) - self.sequence_length - self.prediction_horizon + 1):\n",
    "                seq = feature_data[i:i+self.sequence_length]\n",
    "                target = feature_data[i+self.sequence_length:i+self.sequence_length+self.prediction_horizon,0]\n",
    "                sequences.append(seq)\n",
    "                targets.append(target)\n",
    "\n",
    "        return np.array(sequences), np.array(targets)\n",
    "\n",
    "    # ================================\n",
    "    # Build model\n",
    "    # ================================\n",
    "    def build_model(self, input_shape):\n",
    "        model = Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "            LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "            LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dropout(0.2),\n",
    "            Dense(self.prediction_horizon, activation=\"linear\")\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(0.001), loss=\"mse\", metrics=[\"mae\"])\n",
    "        return model\n",
    "\n",
    "    # ================================\n",
    "    # Temporal split\n",
    "    # ================================\n",
    "    def temporal_split(self, X, y, val_ratio=0.2):\n",
    "        split_index = int(len(X)*(1-val_ratio))\n",
    "        return X[:split_index], X[split_index:], y[:split_index], y[split_index:]\n",
    "\n",
    "    # ================================\n",
    "    # Training\n",
    "    # ================================\n",
    "    def train(self, csv_file_path, validation_split=0.2, epochs=50):\n",
    "        data = self.load_and_preprocess_data(csv_file_path)\n",
    "        X, y = self.create_sequences(data)\n",
    "\n",
    "        X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "        X_scaled = self.scaler.fit_transform(X_reshaped).reshape(X.shape)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = self.temporal_split(X_scaled, y, validation_split)\n",
    "        self.model = self.build_model((X.shape[1], X.shape[2]))\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)\n",
    "        ]\n",
    "\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        return data, history\n",
    "\n",
    "    # ================================\n",
    "    # Prediksi per geo_hash\n",
    "    # ================================\n",
    "    def predict_next_day_30min_filtered(self, data, geo_hash):\n",
    "        \"\"\"\n",
    "        Prediksi hanya untuk slot yang pernah ada di data historis.\n",
    "        Slot yang tidak pernah ada akan diabaikan (NaN).\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model belum di-train!\")\n",
    "\n",
    "        geo_data = data[data[\"origin_geo_hash\"]==geo_hash].sort_values([\"request_date\",\"slot_30min\"])\n",
    "        features = [\"request_count\",\"slot_30min\",\"day_of_week\",\"is_weekend\",\"geo_encoded\"]\n",
    "\n",
    "        if len(geo_data) < self.sequence_length:\n",
    "            raise ValueError(f\"Tidak cukup data untuk geo_hash {geo_hash}\")\n",
    "\n",
    "        # Slot historis yang ada\n",
    "        existing_slots = geo_data[\"slot_30min\"].unique()\n",
    "\n",
    "        # Ambil sequence terakhir untuk prediksi\n",
    "        last_seq = geo_data[features].tail(self.sequence_length).values\n",
    "        last_seq[:,0] = np.log1p(last_seq[:,0])  # log-transform\n",
    "        seq_scaled = self.scaler.transform(last_seq).reshape(1,self.sequence_length,len(features))\n",
    "        pred_full = self.model.predict(seq_scaled, verbose=0)[0]\n",
    "\n",
    "        # Inverse log-transform\n",
    "        pred_full = np.expm1(pred_full)\n",
    "        pred_full = np.maximum(0, pred_full)\n",
    "\n",
    "        tomorrow_date = geo_data[\"request_date\"].max() + timedelta(days=1)\n",
    "\n",
    "        # Hanya buat prediksi untuk slot yang ada\n",
    "        pred_dict = {\n",
    "            \"geo_hash\": [],\n",
    "            \"date\": [],\n",
    "            \"slot_30min\": [],\n",
    "            \"predicted_request_count\": []\n",
    "        }\n",
    "\n",
    "        for i, slot in enumerate(range(len(pred_full))):\n",
    "            if slot in existing_slots:\n",
    "                pred_dict[\"geo_hash\"].append(geo_hash)\n",
    "                pred_dict[\"date\"].append(tomorrow_date)\n",
    "                pred_dict[\"slot_30min\"].append(slot)\n",
    "                pred_dict[\"predicted_request_count\"].append(pred_full[i])\n",
    "            else:\n",
    "                # slot tidak ada di historis → dilewati / bisa diisi NaN jika mau\n",
    "                continue\n",
    "\n",
    "        return pd.DataFrame(pred_dict)\n",
    "    \n",
    "    # ================================\n",
    "    # Prediksi semua geo_hash\n",
    "    # ================================\n",
    "    def predict_all_next_day_30min_filtered(self, data):\n",
    "        \"\"\"\n",
    "        Prediksi untuk semua geo_hash, hanya untuk slot yang ada di historis.\n",
    "        Slot yang tidak ada di historis akan diabaikan.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for geo_hash in data[\"origin_geo_hash\"].unique():\n",
    "            try:\n",
    "                df_pred = self.predict_next_day_30min_filtered(data, geo_hash)\n",
    "                results.append(df_pred)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {geo_hash}, error: {e}\")\n",
    "        if results:\n",
    "            return pd.concat(results, ignore_index=True)\n",
    "        else:\n",
    "            # Jika tidak ada prediksi sama sekali\n",
    "            return pd.DataFrame(columns=[\"geo_hash\", \"date\", \"slot_30min\", \"predicted_request_count\"])\n",
    "    \n",
    "    # ================================\n",
    "    # Evaluasi\n",
    "    # ================================\n",
    "    def evaluate_yesterday_30min(self, data, yesterday_predictions):\n",
    "        actuals = data.merge(\n",
    "            yesterday_predictions[[\"geo_hash\",\"date\",\"slot_30min\"]],\n",
    "            left_on=[\"origin_geo_hash\",\"request_date\",\"slot_30min\"],\n",
    "            right_on=[\"geo_hash\",\"date\",\"slot_30min\"],\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        actuals = actuals.rename(columns={\"request_count\":\"actual_request_count\"})\n",
    "        merged = pd.merge(yesterday_predictions, actuals, on=[\"geo_hash\",\"date\",\"slot_30min\"], how=\"inner\")\n",
    "\n",
    "        if merged.empty:\n",
    "            print(\"⚠️ Tidak ada data aktual untuk dievaluasi.\")\n",
    "            return None\n",
    "\n",
    "        mae = mean_absolute_error(merged[\"actual_request_count\"], merged[\"predicted_request_count\"])\n",
    "        rmse = mean_squared_error(merged[\"actual_request_count\"], merged[\"predicted_request_count\"], squared=False)\n",
    "        print(f\"Evaluasi untuk {merged['date'].iloc[0].date()}: MAE={mae:.2f}, RMSE={rmse:.2f}\")\n",
    "        return merged, {\"MAE\": mae, \"RMSE\": rmse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f81a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ File data_29_09_2025.csv tidak ditemukan, menggunakan histori yang ada saja.\n",
      "Epoch 1/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 198ms/step - loss: 1.3024 - mae: 0.9699 - val_loss: 1.4876 - val_mae: 1.0550 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 1.1393 - mae: 0.8962 - val_loss: 1.1129 - val_mae: 0.8756 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.9310 - mae: 0.7856 - val_loss: 0.8685 - val_mae: 0.7523 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.7702 - mae: 0.7013 - val_loss: 0.6938 - val_mae: 0.6545 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.6471 - mae: 0.6384 - val_loss: 0.5723 - val_mae: 0.5743 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.5711 - mae: 0.5946 - val_loss: 0.4987 - val_mae: 0.5163 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.5402 - mae: 0.5753 - val_loss: 0.4742 - val_mae: 0.4989 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.5015 - mae: 0.5468 - val_loss: 0.4577 - val_mae: 0.4817 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.4817 - mae: 0.5340 - val_loss: 0.4665 - val_mae: 0.5004 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.4692 - mae: 0.5238 - val_loss: 0.4294 - val_mae: 0.4364 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.4606 - mae: 0.5157 - val_loss: 0.4195 - val_mae: 0.4204 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.4513 - mae: 0.5084 - val_loss: 0.4264 - val_mae: 0.4313 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.4486 - mae: 0.5065 - val_loss: 0.4396 - val_mae: 0.4597 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.4481 - mae: 0.5043 - val_loss: 0.4370 - val_mae: 0.4552 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.4425 - mae: 0.4996 - val_loss: 0.4270 - val_mae: 0.4343 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.4411 - mae: 0.4982 - val_loss: 0.4220 - val_mae: 0.4216 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.4337 - mae: 0.4921 - val_loss: 0.4196 - val_mae: 0.4158 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.4332 - mae: 0.4917 - val_loss: 0.4263 - val_mae: 0.4330 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.4329 - mae: 0.4926 - val_loss: 0.4125 - val_mae: 0.4037 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.4287 - mae: 0.4863 - val_loss: 0.4209 - val_mae: 0.4187 - learning_rate: 5.0000e-04\n",
      "✅ Model selesai di-train.\n",
      "Skipping qpz6e8, error: Tidak cukup data untuk geo_hash qpz6e8\n",
      "Skipping qqgb0x, error: Tidak cukup data untuk geo_hash qqgb0x\n",
      "Skipping qqgeut, error: Tidak cukup data untuk geo_hash qqgeut\n",
      "Skipping qqgfmy, error: Tidak cukup data untuk geo_hash qqgfmy\n",
      "Skipping qqgfps, error: Tidak cukup data untuk geo_hash qqgfps\n",
      "Skipping qqgfqd, error: Tidak cukup data untuk geo_hash qqgfqd\n",
      "Skipping qqgfqp, error: Tidak cukup data untuk geo_hash qqgfqp\n",
      "Skipping qqgfqr, error: Tidak cukup data untuk geo_hash qqgfqr\n",
      "Skipping qqgfst, error: Tidak cukup data untuk geo_hash qqgfst\n",
      "Skipping qqgftc, error: Tidak cukup data untuk geo_hash qqgftc\n",
      "Skipping qqgfw1, error: Tidak cukup data untuk geo_hash qqgfw1\n",
      "Skipping qqgfyk, error: Tidak cukup data untuk geo_hash qqgfyk\n",
      "Skipping qqgfz2, error: Tidak cukup data untuk geo_hash qqgfz2\n",
      "Skipping qqgfzh, error: Tidak cukup data untuk geo_hash qqgfzh\n",
      "Skipping qqggc5, error: Tidak cukup data untuk geo_hash qqggc5\n",
      "Skipping qqgggv, error: Tidak cukup data untuk geo_hash qqgggv\n",
      "Skipping qqggn2, error: Tidak cukup data untuk geo_hash qqggn2\n",
      "Skipping qqggny, error: Tidak cukup data untuk geo_hash qqggny\n",
      "Skipping qqggpw, error: Tidak cukup data untuk geo_hash qqggpw\n",
      "Skipping qqggqm, error: Tidak cukup data untuk geo_hash qqggqm\n",
      "Skipping qqggqz, error: Tidak cukup data untuk geo_hash qqggqz\n",
      "Skipping qqggrf, error: Tidak cukup data untuk geo_hash qqggrf\n",
      "Skipping qqggt4, error: Tidak cukup data untuk geo_hash qqggt4\n",
      "Skipping qqggtd, error: Tidak cukup data untuk geo_hash qqggtd\n",
      "Skipping qqggtt, error: Tidak cukup data untuk geo_hash qqggtt\n",
      "Skipping qqggvh, error: Tidak cukup data untuk geo_hash qqggvh\n",
      "Skipping qqggw5, error: Tidak cukup data untuk geo_hash qqggw5\n",
      "Skipping qqggwt, error: Tidak cukup data untuk geo_hash qqggwt\n",
      "Skipping qqggx5, error: Tidak cukup data untuk geo_hash qqggx5\n",
      "Skipping qqggx6, error: Tidak cukup data untuk geo_hash qqggx6\n",
      "Skipping qqggx8, error: Tidak cukup data untuk geo_hash qqggx8\n",
      "Skipping qqggxx, error: Tidak cukup data untuk geo_hash qqggxx\n",
      "Skipping qqggy8, error: Tidak cukup data untuk geo_hash qqggy8\n",
      "Skipping qqggyc, error: Tidak cukup data untuk geo_hash qqggyc\n",
      "Skipping qqggyr, error: Tidak cukup data untuk geo_hash qqggyr\n",
      "Skipping qqggz1, error: Tidak cukup data untuk geo_hash qqggz1\n",
      "Skipping qqggz5, error: Tidak cukup data untuk geo_hash qqggz5\n",
      "Skipping qqggzr, error: Tidak cukup data untuk geo_hash qqggzr\n",
      "Skipping qqgmpg, error: Tidak cukup data untuk geo_hash qqgmpg\n",
      "Skipping qqgmpk, error: Tidak cukup data untuk geo_hash qqgmpk\n",
      "Skipping qqgmtt, error: Tidak cukup data untuk geo_hash qqgmtt\n",
      "Skipping qqgsr1, error: Tidak cukup data untuk geo_hash qqgsr1\n",
      "Skipping qqgsxx, error: Tidak cukup data untuk geo_hash qqgsxx\n",
      "Skipping qqgu2n, error: Tidak cukup data untuk geo_hash qqgu2n\n",
      "Skipping qqgu3f, error: Tidak cukup data untuk geo_hash qqgu3f\n",
      "Skipping qqgu4f, error: Tidak cukup data untuk geo_hash qqgu4f\n",
      "Skipping qqgu4q, error: Tidak cukup data untuk geo_hash qqgu4q\n",
      "Skipping qqgu4s, error: Tidak cukup data untuk geo_hash qqgu4s\n",
      "Skipping qqgu58, error: Tidak cukup data untuk geo_hash qqgu58\n",
      "Skipping qqgu5p, error: Tidak cukup data untuk geo_hash qqgu5p\n",
      "Skipping qqgu5s, error: Tidak cukup data untuk geo_hash qqgu5s\n",
      "Skipping qqgu6h, error: Tidak cukup data untuk geo_hash qqgu6h\n",
      "Skipping qqgu6r, error: Tidak cukup data untuk geo_hash qqgu6r\n",
      "Skipping qqgu75, error: Tidak cukup data untuk geo_hash qqgu75\n",
      "Skipping qqgu93, error: Tidak cukup data untuk geo_hash qqgu93\n",
      "Skipping qqgu9v, error: Tidak cukup data untuk geo_hash qqgu9v\n",
      "Skipping qqgucs, error: Tidak cukup data untuk geo_hash qqgucs\n",
      "Skipping qqgud5, error: Tidak cukup data untuk geo_hash qqgud5\n",
      "Skipping qqgudx, error: Tidak cukup data untuk geo_hash qqgudx\n",
      "Skipping qqguf6, error: Tidak cukup data untuk geo_hash qqguf6\n",
      "Skipping qqguf8, error: Tidak cukup data untuk geo_hash qqguf8\n",
      "Skipping qqgug0, error: Tidak cukup data untuk geo_hash qqgug0\n",
      "Skipping qqgug5, error: Tidak cukup data untuk geo_hash qqgug5\n",
      "Skipping qqgugn, error: Tidak cukup data untuk geo_hash qqgugn\n",
      "Skipping qqguh3, error: Tidak cukup data untuk geo_hash qqguh3\n",
      "Skipping qqguh4, error: Tidak cukup data untuk geo_hash qqguh4\n",
      "Skipping qqguhk, error: Tidak cukup data untuk geo_hash qqguhk\n",
      "Skipping qqguj8, error: Tidak cukup data untuk geo_hash qqguj8\n",
      "Skipping qqgujk, error: Tidak cukup data untuk geo_hash qqgujk\n",
      "Skipping qqgujy, error: Tidak cukup data untuk geo_hash qqgujy\n",
      "Skipping qqguk0, error: Tidak cukup data untuk geo_hash qqguk0\n",
      "Skipping qqguk3, error: Tidak cukup data untuk geo_hash qqguk3\n",
      "Skipping qqguk9, error: Tidak cukup data untuk geo_hash qqguk9\n",
      "Skipping qqgukp, error: Tidak cukup data untuk geo_hash qqgukp\n",
      "Skipping qqgumg, error: Tidak cukup data untuk geo_hash qqgumg\n",
      "Skipping qqgumz, error: Tidak cukup data untuk geo_hash qqgumz\n",
      "Skipping qqgun4, error: Tidak cukup data untuk geo_hash qqgun4\n",
      "Skipping qqgunh, error: Tidak cukup data untuk geo_hash qqgunh\n",
      "Skipping qqgunn, error: Tidak cukup data untuk geo_hash qqgunn\n",
      "Skipping qqgunw, error: Tidak cukup data untuk geo_hash qqgunw\n",
      "Skipping qqguny, error: Tidak cukup data untuk geo_hash qqguny\n",
      "Skipping qqgunz, error: Tidak cukup data untuk geo_hash qqgunz\n",
      "Skipping qqgupk, error: Tidak cukup data untuk geo_hash qqgupk\n",
      "Skipping qqguq5, error: Tidak cukup data untuk geo_hash qqguq5\n",
      "Skipping qqguqb, error: Tidak cukup data untuk geo_hash qqguqb\n",
      "Skipping qqguqm, error: Tidak cukup data untuk geo_hash qqguqm\n",
      "Skipping qqguqp, error: Tidak cukup data untuk geo_hash qqguqp\n",
      "Skipping qqguqv, error: Tidak cukup data untuk geo_hash qqguqv\n",
      "Skipping qqgur1, error: Tidak cukup data untuk geo_hash qqgur1\n",
      "Skipping qqgur7, error: Tidak cukup data untuk geo_hash qqgur7\n",
      "Skipping qqgurf, error: Tidak cukup data untuk geo_hash qqgurf\n",
      "Skipping qqgurq, error: Tidak cukup data untuk geo_hash qqgurq\n",
      "Skipping qqgurz, error: Tidak cukup data untuk geo_hash qqgurz\n",
      "Skipping qqgut0, error: Tidak cukup data untuk geo_hash qqgut0\n",
      "Skipping qqgut7, error: Tidak cukup data untuk geo_hash qqgut7\n",
      "Skipping qqgut8, error: Tidak cukup data untuk geo_hash qqgut8\n",
      "Skipping qqguu1, error: Tidak cukup data untuk geo_hash qqguu1\n",
      "Skipping qqguu4, error: Tidak cukup data untuk geo_hash qqguu4\n",
      "Skipping qqguuc, error: Tidak cukup data untuk geo_hash qqguuc\n",
      "Skipping qqguut, error: Tidak cukup data untuk geo_hash qqguut\n",
      "Skipping qqguux, error: Tidak cukup data untuk geo_hash qqguux\n",
      "Skipping qqguv3, error: Tidak cukup data untuk geo_hash qqguv3\n",
      "Skipping qqguvk, error: Tidak cukup data untuk geo_hash qqguvk\n",
      "Skipping qqguvs, error: Tidak cukup data untuk geo_hash qqguvs\n",
      "Skipping qqguvt, error: Tidak cukup data untuk geo_hash qqguvt\n",
      "Skipping qqguvu, error: Tidak cukup data untuk geo_hash qqguvu\n",
      "Skipping qqguvv, error: Tidak cukup data untuk geo_hash qqguvv\n",
      "Skipping qqguw3, error: Tidak cukup data untuk geo_hash qqguw3\n",
      "Skipping qqguw6, error: Tidak cukup data untuk geo_hash qqguw6\n",
      "Skipping qqguw9, error: Tidak cukup data untuk geo_hash qqguw9\n",
      "Skipping qqguwc, error: Tidak cukup data untuk geo_hash qqguwc\n",
      "Skipping qqguwe, error: Tidak cukup data untuk geo_hash qqguwe\n",
      "Skipping qqguwf, error: Tidak cukup data untuk geo_hash qqguwf\n",
      "Skipping qqguwg, error: Tidak cukup data untuk geo_hash qqguwg\n",
      "Skipping qqguwr, error: Tidak cukup data untuk geo_hash qqguwr\n",
      "Skipping qqguws, error: Tidak cukup data untuk geo_hash qqguws\n",
      "Skipping qqguwt, error: Tidak cukup data untuk geo_hash qqguwt\n",
      "Skipping qqguwu, error: Tidak cukup data untuk geo_hash qqguwu\n",
      "Skipping qqguwv, error: Tidak cukup data untuk geo_hash qqguwv\n",
      "Skipping qqguww, error: Tidak cukup data untuk geo_hash qqguww\n",
      "Skipping qqguwz, error: Tidak cukup data untuk geo_hash qqguwz\n",
      "Skipping qqgux3, error: Tidak cukup data untuk geo_hash qqgux3\n",
      "Skipping qqgux5, error: Tidak cukup data untuk geo_hash qqgux5\n",
      "Skipping qqgux6, error: Tidak cukup data untuk geo_hash qqgux6\n",
      "Skipping qqguxb, error: Tidak cukup data untuk geo_hash qqguxb\n",
      "Skipping qqguxh, error: Tidak cukup data untuk geo_hash qqguxh\n",
      "Skipping qqguxr, error: Tidak cukup data untuk geo_hash qqguxr\n",
      "Skipping qqguy3, error: Tidak cukup data untuk geo_hash qqguy3\n",
      "Skipping qqguyc, error: Tidak cukup data untuk geo_hash qqguyc\n",
      "Skipping qqguyd, error: Tidak cukup data untuk geo_hash qqguyd\n",
      "Skipping qqguye, error: Tidak cukup data untuk geo_hash qqguye\n",
      "Skipping qqguyf, error: Tidak cukup data untuk geo_hash qqguyf\n",
      "Skipping qqguyj, error: Tidak cukup data untuk geo_hash qqguyj\n",
      "Skipping qqguyp, error: Tidak cukup data untuk geo_hash qqguyp\n",
      "Skipping qqguys, error: Tidak cukup data untuk geo_hash qqguys\n",
      "Skipping qqguyu, error: Tidak cukup data untuk geo_hash qqguyu\n",
      "Skipping qqguyz, error: Tidak cukup data untuk geo_hash qqguyz\n",
      "Skipping qqguz0, error: Tidak cukup data untuk geo_hash qqguz0\n",
      "Skipping qqguz2, error: Tidak cukup data untuk geo_hash qqguz2\n",
      "Skipping qqguzb, error: Tidak cukup data untuk geo_hash qqguzb\n",
      "Skipping qqguzg, error: Tidak cukup data untuk geo_hash qqguzg\n",
      "Skipping qqguzj, error: Tidak cukup data untuk geo_hash qqguzj\n",
      "Skipping qqguzr, error: Tidak cukup data untuk geo_hash qqguzr\n",
      "Skipping qqguzv, error: Tidak cukup data untuk geo_hash qqguzv\n",
      "Skipping qqgv43, error: Tidak cukup data untuk geo_hash qqgv43\n",
      "Skipping qqgv59, error: Tidak cukup data untuk geo_hash qqgv59\n",
      "Skipping qqgv6v, error: Tidak cukup data untuk geo_hash qqgv6v\n",
      "Skipping qqgvh1, error: Tidak cukup data untuk geo_hash qqgvh1\n",
      "Skipping qqgvhd, error: Tidak cukup data untuk geo_hash qqgvhd\n",
      "Skipping qqgvhk, error: Tidak cukup data untuk geo_hash qqgvhk\n",
      "Skipping qqgvhz, error: Tidak cukup data untuk geo_hash qqgvhz\n",
      "Skipping qqgvkb, error: Tidak cukup data untuk geo_hash qqgvkb\n",
      "Skipping qqgvkh, error: Tidak cukup data untuk geo_hash qqgvkh\n",
      "Skipping qqgvn1, error: Tidak cukup data untuk geo_hash qqgvn1\n",
      "Skipping qqgvn8, error: Tidak cukup data untuk geo_hash qqgvn8\n",
      "Skipping qqgvne, error: Tidak cukup data untuk geo_hash qqgvne\n",
      "Skipping qqgvnm, error: Tidak cukup data untuk geo_hash qqgvnm\n",
      "Skipping qqgvnn, error: Tidak cukup data untuk geo_hash qqgvnn\n",
      "Skipping qqgvnr, error: Tidak cukup data untuk geo_hash qqgvnr\n",
      "Skipping qqgvnu, error: Tidak cukup data untuk geo_hash qqgvnu\n",
      "Skipping qqgvp0, error: Tidak cukup data untuk geo_hash qqgvp0\n",
      "Skipping qqgvp3, error: Tidak cukup data untuk geo_hash qqgvp3\n",
      "Skipping qqgvp9, error: Tidak cukup data untuk geo_hash qqgvp9\n",
      "Skipping qqgvpc, error: Tidak cukup data untuk geo_hash qqgvpc\n",
      "Skipping qqgvpd, error: Tidak cukup data untuk geo_hash qqgvpd\n",
      "Skipping qqgvph, error: Tidak cukup data untuk geo_hash qqgvph\n",
      "Skipping qqsxbh, error: Tidak cukup data untuk geo_hash qqsxbh\n",
      "Skipping qqsyhq, error: Tidak cukup data untuk geo_hash qqsyhq\n",
      "Skipping qqtn3d, error: Tidak cukup data untuk geo_hash qqtn3d\n",
      "Skipping qqtttz, error: Tidak cukup data untuk geo_hash qqtttz\n",
      "Skipping qqttv8, error: Tidak cukup data untuk geo_hash qqttv8\n",
      "Skipping qqu08u, error: Tidak cukup data untuk geo_hash qqu08u\n",
      "Skipping qqu09e, error: Tidak cukup data untuk geo_hash qqu09e\n",
      "Skipping qqu1ez, error: Tidak cukup data untuk geo_hash qqu1ez\n",
      "Skipping qqu1nn, error: Tidak cukup data untuk geo_hash qqu1nn\n",
      "Skipping qqu2n8, error: Tidak cukup data untuk geo_hash qqu2n8\n",
      "Skipping qqu2rd, error: Tidak cukup data untuk geo_hash qqu2rd\n",
      "Skipping qqu2vm, error: Tidak cukup data untuk geo_hash qqu2vm\n",
      "Skipping qqu2zj, error: Tidak cukup data untuk geo_hash qqu2zj\n",
      "Skipping qqu30r, error: Tidak cukup data untuk geo_hash qqu30r\n",
      "Skipping qqu486, error: Tidak cukup data untuk geo_hash qqu486\n",
      "Skipping qqu505, error: Tidak cukup data untuk geo_hash qqu505\n",
      "Skipping qqu58z, error: Tidak cukup data untuk geo_hash qqu58z\n",
      "Skipping qqu59s, error: Tidak cukup data untuk geo_hash qqu59s\n",
      "Skipping qqu5bh, error: Tidak cukup data untuk geo_hash qqu5bh\n",
      "Skipping qqu5br, error: Tidak cukup data untuk geo_hash qqu5br\n",
      "Skipping qqu5d7, error: Tidak cukup data untuk geo_hash qqu5d7\n",
      "Skipping qqu5f0, error: Tidak cukup data untuk geo_hash qqu5f0\n",
      "Skipping qqu5fj, error: Tidak cukup data untuk geo_hash qqu5fj\n",
      "Skipping qqu5vz, error: Tidak cukup data untuk geo_hash qqu5vz\n",
      "Skipping qqu5yc, error: Tidak cukup data untuk geo_hash qqu5yc\n",
      "Skipping qqu5yq, error: Tidak cukup data untuk geo_hash qqu5yq\n",
      "Skipping qqu6uc, error: Tidak cukup data untuk geo_hash qqu6uc\n",
      "Skipping qqu7bf, error: Tidak cukup data untuk geo_hash qqu7bf\n",
      "Skipping qqu7dr, error: Tidak cukup data untuk geo_hash qqu7dr\n",
      "Skipping qqu7mx, error: Tidak cukup data untuk geo_hash qqu7mx\n",
      "Skipping qqu7t6, error: Tidak cukup data untuk geo_hash qqu7t6\n",
      "Skipping qqu81h, error: Tidak cukup data untuk geo_hash qqu81h\n",
      "Skipping qqu82n, error: Tidak cukup data untuk geo_hash qqu82n\n",
      "Skipping qqu832, error: Tidak cukup data untuk geo_hash qqu832\n",
      "Skipping qqu837, error: Tidak cukup data untuk geo_hash qqu837\n",
      "Skipping qqu83j, error: Tidak cukup data untuk geo_hash qqu83j\n",
      "Skipping qqu85b, error: Tidak cukup data untuk geo_hash qqu85b\n",
      "Skipping qqu86t, error: Tidak cukup data untuk geo_hash qqu86t\n",
      "Skipping qqu88q, error: Tidak cukup data untuk geo_hash qqu88q\n",
      "Skipping qqu88z, error: Tidak cukup data untuk geo_hash qqu88z\n",
      "Skipping qqu89b, error: Tidak cukup data untuk geo_hash qqu89b\n",
      "Skipping qqu8b6, error: Tidak cukup data untuk geo_hash qqu8b6\n",
      "Skipping qqu8dv, error: Tidak cukup data untuk geo_hash qqu8dv\n",
      "Skipping qqu9pg, error: Tidak cukup data untuk geo_hash qqu9pg\n",
      "Skipping qqudev, error: Tidak cukup data untuk geo_hash qqudev\n",
      "Skipping qquh05, error: Tidak cukup data untuk geo_hash qquh05\n",
      "Skipping qquh14, error: Tidak cukup data untuk geo_hash qquh14\n",
      "Skipping qquh16, error: Tidak cukup data untuk geo_hash qquh16\n",
      "Skipping qquh2b, error: Tidak cukup data untuk geo_hash qquh2b\n",
      "Skipping qquh2c, error: Tidak cukup data untuk geo_hash qquh2c\n",
      "Skipping qquh3t, error: Tidak cukup data untuk geo_hash qquh3t\n",
      "Skipping qquh4v, error: Tidak cukup data untuk geo_hash qquh4v\n",
      "Skipping qquh53, error: Tidak cukup data untuk geo_hash qquh53\n",
      "Skipping qquh5z, error: Tidak cukup data untuk geo_hash qquh5z\n",
      "Skipping qquh64, error: Tidak cukup data untuk geo_hash qquh64\n",
      "Skipping qquh6q, error: Tidak cukup data untuk geo_hash qquh6q\n",
      "Skipping qquh6t, error: Tidak cukup data untuk geo_hash qquh6t\n",
      "Skipping qquh6w, error: Tidak cukup data untuk geo_hash qquh6w\n",
      "Skipping qquh7n, error: Tidak cukup data untuk geo_hash qquh7n\n",
      "Skipping qquh8r, error: Tidak cukup data untuk geo_hash qquh8r\n",
      "Skipping qquh97, error: Tidak cukup data untuk geo_hash qquh97\n",
      "Skipping qquh9c, error: Tidak cukup data untuk geo_hash qquh9c\n",
      "Skipping qquhb1, error: Tidak cukup data untuk geo_hash qquhb1\n",
      "Skipping qquhb2, error: Tidak cukup data untuk geo_hash qquhb2\n",
      "Skipping qquhbd, error: Tidak cukup data untuk geo_hash qquhbd\n",
      "Skipping qquhbp, error: Tidak cukup data untuk geo_hash qquhbp\n",
      "Skipping qquhbz, error: Tidak cukup data untuk geo_hash qquhbz\n",
      "Skipping qquhcu, error: Tidak cukup data untuk geo_hash qquhcu\n",
      "Skipping qquhdc, error: Tidak cukup data untuk geo_hash qquhdc\n",
      "Skipping qquhdf, error: Tidak cukup data untuk geo_hash qquhdf\n",
      "Skipping qquhdy, error: Tidak cukup data untuk geo_hash qquhdy\n",
      "Skipping qquheq, error: Tidak cukup data untuk geo_hash qquheq\n",
      "Skipping qquhes, error: Tidak cukup data untuk geo_hash qquhes\n",
      "Skipping qquhf3, error: Tidak cukup data untuk geo_hash qquhf3\n",
      "Skipping qquhfg, error: Tidak cukup data untuk geo_hash qquhfg\n",
      "Skipping qquhfn, error: Tidak cukup data untuk geo_hash qquhfn\n",
      "Skipping qquhft, error: Tidak cukup data untuk geo_hash qquhft\n",
      "Skipping qquhfy, error: Tidak cukup data untuk geo_hash qquhfy\n",
      "Skipping qquhg4, error: Tidak cukup data untuk geo_hash qquhg4\n",
      "Skipping qquhhy, error: Tidak cukup data untuk geo_hash qquhhy\n",
      "Skipping qquhmt, error: Tidak cukup data untuk geo_hash qquhmt\n",
      "Skipping qquhnt, error: Tidak cukup data untuk geo_hash qquhnt\n",
      "Skipping qquhq8, error: Tidak cukup data untuk geo_hash qquhq8\n",
      "Skipping qquhsb, error: Tidak cukup data untuk geo_hash qquhsb\n",
      "Skipping qquj02, error: Tidak cukup data untuk geo_hash qquj02\n",
      "Skipping qquj03, error: Tidak cukup data untuk geo_hash qquj03\n",
      "Skipping qquj0m, error: Tidak cukup data untuk geo_hash qquj0m\n",
      "Skipping qquj0x, error: Tidak cukup data untuk geo_hash qquj0x\n",
      "Skipping qquj0z, error: Tidak cukup data untuk geo_hash qquj0z\n",
      "Skipping qquk18, error: Tidak cukup data untuk geo_hash qquk18\n",
      "Skipping qquk49, error: Tidak cukup data untuk geo_hash qquk49\n",
      "Skipping qqv0k2, error: Tidak cukup data untuk geo_hash qqv0k2\n",
      "Skipping qqv1y1, error: Tidak cukup data untuk geo_hash qqv1y1\n",
      "Skipping qqv2dw, error: Tidak cukup data untuk geo_hash qqv2dw\n",
      "Skipping qqv50t, error: Tidak cukup data untuk geo_hash qqv50t\n",
      "Skipping qqv8gf, error: Tidak cukup data untuk geo_hash qqv8gf\n",
      "Skipping qqv8gm, error: Tidak cukup data untuk geo_hash qqv8gm\n",
      "Skipping qqvbu2, error: Tidak cukup data untuk geo_hash qqvbu2\n",
      "Skipping qqvbxr, error: Tidak cukup data untuk geo_hash qqvbxr\n",
      "Skipping qqvby3, error: Tidak cukup data untuk geo_hash qqvby3\n",
      "Skipping qqvbzc, error: Tidak cukup data untuk geo_hash qqvbzc\n",
      "Skipping qqvbze, error: Tidak cukup data untuk geo_hash qqvbze\n",
      "Skipping qqw7xx, error: Tidak cukup data untuk geo_hash qqw7xx\n",
      "Skipping qqw7xz, error: Tidak cukup data untuk geo_hash qqw7xz\n",
      "Skipping qqw7zw, error: Tidak cukup data untuk geo_hash qqw7zw\n",
      "Skipping qqweb6, error: Tidak cukup data untuk geo_hash qqweb6\n",
      "Skipping qqwhp7, error: Tidak cukup data untuk geo_hash qqwhp7\n",
      "Skipping qqwry0, error: Tidak cukup data untuk geo_hash qqwry0\n",
      "Skipping qqwuct, error: Tidak cukup data untuk geo_hash qqwuct\n",
      "Skipping qqwv08, error: Tidak cukup data untuk geo_hash qqwv08\n",
      "Skipping qqww69, error: Tidak cukup data untuk geo_hash qqww69\n",
      "Skipping qqwx27, error: Tidak cukup data untuk geo_hash qqwx27\n",
      "Skipping qqwx2g, error: Tidak cukup data untuk geo_hash qqwx2g\n",
      "Skipping qqwxb8, error: Tidak cukup data untuk geo_hash qqwxb8\n",
      "Skipping qqwxbg, error: Tidak cukup data untuk geo_hash qqwxbg\n",
      "Skipping qqwzsj, error: Tidak cukup data untuk geo_hash qqwzsj\n",
      "Skipping qqy08y, error: Tidak cukup data untuk geo_hash qqy08y\n",
      "Skipping qqy2n8, error: Tidak cukup data untuk geo_hash qqy2n8\n",
      "Skipping qqy2pf, error: Tidak cukup data untuk geo_hash qqy2pf\n",
      "Skipping qqy2pp, error: Tidak cukup data untuk geo_hash qqy2pp\n",
      "Skipping qqy2pv, error: Tidak cukup data untuk geo_hash qqy2pv\n",
      "Skipping qqy80u, error: Tidak cukup data untuk geo_hash qqy80u\n",
      "Skipping qqy819, error: Tidak cukup data untuk geo_hash qqy819\n",
      "Skipping qqy81y, error: Tidak cukup data untuk geo_hash qqy81y\n",
      "Skipping qqy828, error: Tidak cukup data untuk geo_hash qqy828\n",
      "Skipping qqy82d, error: Tidak cukup data untuk geo_hash qqy82d\n",
      "Skipping qqydr0, error: Tidak cukup data untuk geo_hash qqydr0\n",
      "Skipping qr3g1m, error: Tidak cukup data untuk geo_hash qr3g1m\n",
      "Skipping qr3jkb, error: Tidak cukup data untuk geo_hash qr3jkb\n",
      "Skipping qr4c6b, error: Tidak cukup data untuk geo_hash qr4c6b\n",
      "Skipping qr4c6y, error: Tidak cukup data untuk geo_hash qr4c6y\n",
      "Skipping qr4cs0, error: Tidak cukup data untuk geo_hash qr4cs0\n",
      "Skipping qr4fuk, error: Tidak cukup data untuk geo_hash qr4fuk\n",
      "Skipping qr6rp6, error: Tidak cukup data untuk geo_hash qr6rp6\n",
      "Skipping qr6rpc, error: Tidak cukup data untuk geo_hash qr6rpc\n",
      "Skipping qr6rpd, error: Tidak cukup data untuk geo_hash qr6rpd\n",
      "Skipping qr6rpy, error: Tidak cukup data untuk geo_hash qr6rpy\n",
      "Skipping qr6rqc, error: Tidak cukup data untuk geo_hash qr6rqc\n",
      "Skipping qr6wbq, error: Tidak cukup data untuk geo_hash qr6wbq\n",
      "Skipping qr6x0p, error: Tidak cukup data untuk geo_hash qr6x0p\n",
      "Skipping qrvxxy, error: Tidak cukup data untuk geo_hash qrvxxy\n",
      "Skipping qw3ytk, error: Tidak cukup data untuk geo_hash qw3ytk\n",
      "Skipping qw3yug, error: Tidak cukup data untuk geo_hash qw3yug\n",
      "Skipping qw3ywj, error: Tidak cukup data untuk geo_hash qw3ywj\n",
      "Skipping qw6x4k, error: Tidak cukup data untuk geo_hash qw6x4k\n",
      "Skipping qw84f6, error: Tidak cukup data untuk geo_hash qw84f6\n",
      "Skipping qw84g4, error: Tidak cukup data untuk geo_hash qw84g4\n",
      "Skipping qw8hke, error: Tidak cukup data untuk geo_hash qw8hke\n",
      "Skipping qw8hy2, error: Tidak cukup data untuk geo_hash qw8hy2\n",
      "Skipping qw8k3n, error: Tidak cukup data untuk geo_hash qw8k3n\n",
      "Skipping qw8nen, error: Tidak cukup data untuk geo_hash qw8nen\n",
      "Skipping qw8nhq, error: Tidak cukup data untuk geo_hash qw8nhq\n",
      "Skipping qw8nj4, error: Tidak cukup data untuk geo_hash qw8nj4\n",
      "Skipping qw8nmy, error: Tidak cukup data untuk geo_hash qw8nmy\n",
      "Skipping qw8nqr, error: Tidak cukup data untuk geo_hash qw8nqr\n",
      "Skipping qw8nte, error: Tidak cukup data untuk geo_hash qw8nte\n",
      "Skipping qw8p68, error: Tidak cukup data untuk geo_hash qw8p68\n",
      "Skipping qxg0gp, error: Tidak cukup data untuk geo_hash qxg0gp\n",
      "Skipping qxg159, error: Tidak cukup data untuk geo_hash qxg159\n",
      "Skipping qxhfmb, error: Tidak cukup data untuk geo_hash qxhfmb\n",
      "Skipping qxhfsc, error: Tidak cukup data untuk geo_hash qxhfsc\n",
      "Skipping qxhfsy, error: Tidak cukup data untuk geo_hash qxhfsy\n",
      "Skipping qxhftd, error: Tidak cukup data untuk geo_hash qxhftd\n",
      "Skipping qxhftz, error: Tidak cukup data untuk geo_hash qxhftz\n",
      "Skipping qxhfwh, error: Tidak cukup data untuk geo_hash qxhfwh\n",
      "Skipping qxhfwj, error: Tidak cukup data untuk geo_hash qxhfwj\n",
      "Skipping qxr153, error: Tidak cukup data untuk geo_hash qxr153\n",
      "Skipping w0whm4, error: Tidak cukup data untuk geo_hash w0whm4\n",
      "Skipping w0wht9, error: Tidak cukup data untuk geo_hash w0wht9\n",
      "Skipping w204gg, error: Tidak cukup data untuk geo_hash w204gg\n",
      "Skipping w204us, error: Tidak cukup data untuk geo_hash w204us\n",
      "Skipping w204ut, error: Tidak cukup data untuk geo_hash w204ut\n",
      "Skipping w21yq4, error: Tidak cukup data untuk geo_hash w21yq4\n",
      "Skipping w21yrk, error: Tidak cukup data untuk geo_hash w21yrk\n",
      "Skipping w21ywb, error: Tidak cukup data untuk geo_hash w21ywb\n",
      "Skipping w24m1j, error: Tidak cukup data untuk geo_hash w24m1j\n",
      "Skipping w24m4p, error: Tidak cukup data untuk geo_hash w24m4p\n",
      "Skipping w8589q, error: Tidak cukup data untuk geo_hash w8589q\n",
      "Skipping w858c1, error: Tidak cukup data untuk geo_hash w858c1\n",
      "✅ Prediksi untuk 29_09_2025 tersimpan di prediksi_29_09_2025.csv\n",
      "⚠️ Data aktual untuk 28_09_2025 belum tersedia atau data kosong, evaluasi dilewati.\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 1️⃣ Load dan update histori\n",
    "# =============================\n",
    "historical_file = \"data_historis.csv\"\n",
    "file_new_data = \"data_29_09_2025.csv\"  # ganti sesuai data hari ini\n",
    "\n",
    "# Load data historis\n",
    "if Path(historical_file).exists():\n",
    "    historical_data = pd.read_csv(historical_file)\n",
    "else:\n",
    "    historical_data = pd.DataFrame()  # kalau histori belum ada, buat dataframe kosong\n",
    "    print(\"⚠️ File histori belum ada, membuat dataframe kosong.\")\n",
    "\n",
    "# Tambahkan data baru jika ada\n",
    "if Path(file_new_data).exists():\n",
    "    new_data = pd.read_csv(file_new_data)\n",
    "    historical_data = pd.concat([historical_data, new_data], ignore_index=True)\n",
    "    historical_data.to_csv(historical_file, index=False)\n",
    "    print(f\"✅ Data baru dari {file_new_data} ditambahkan ke histori. Total rows: {len(historical_data)}\")\n",
    "else:\n",
    "    print(f\"⚠️ File {file_new_data} tidak ditemukan, menggunakan histori yang ada saja.\")\n",
    "\n",
    "# =============================\n",
    "# 2️⃣ Inisialisasi dan train model\n",
    "# =============================\n",
    "predictor = TimeSeriesRequestPredictor30Min(sequence_length=144, prediction_horizon=48)\n",
    "\n",
    "if len(historical_data) > 0:\n",
    "    data_preprocessed, history = predictor.train(historical_file, epochs=20)\n",
    "    print(\"✅ Model selesai di-train.\")\n",
    "else:\n",
    "    data_preprocessed = pd.DataFrame()  # kosong jika tidak ada data\n",
    "\n",
    "# =============================\n",
    "# 3️⃣ Prediksi hari berikutnya\n",
    "# =============================\n",
    "if len(data_preprocessed) > 0:\n",
    "    tomorrow_date = (data_preprocessed[\"request_date\"].max() + timedelta(days=1)).strftime(\"%d_%m_%Y\")\n",
    "    predictions = predictor.predict_all_next_day_30min_filtered(data_preprocessed)\n",
    "\n",
    "    # Simpan hasil prediksi\n",
    "    pred_file = f\"prediksi_{tomorrow_date}.csv\"\n",
    "    predictions.to_csv(pred_file, index=False)\n",
    "    print(f\"✅ Prediksi untuk {tomorrow_date} tersimpan di {pred_file}\")\n",
    "else:\n",
    "    print(\"⚠️ Tidak ada data untuk prediksi.\")\n",
    "\n",
    "# =============================\n",
    "# 4️⃣ Evaluasi prediksi kemarin\n",
    "# =============================\n",
    "yesterday_date = (data_preprocessed[\"request_date\"].max()).strftime(\"%d_%m_%Y\") if len(data_preprocessed) > 0 else None\n",
    "file_yesterday_actual = f\"data_{yesterday_date}.csv\" if yesterday_date else None\n",
    "\n",
    "if file_yesterday_actual and Path(file_yesterday_actual).exists() and len(data_preprocessed) > 0:\n",
    "    actual_yesterday = predictor.load_and_preprocess_data(file_yesterday_actual)\n",
    "    eval_results, metrics = predictor.evaluate_yesterday_30min(actual_yesterday, predictions)\n",
    "else:\n",
    "    print(f\"⚠️ Data aktual untuk {yesterday_date} belum tersedia atau data kosong, evaluasi dilewati.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
